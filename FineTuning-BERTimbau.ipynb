{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RogerioPiazzon/trabalhofinalPECE/blob/main/FineTuning-BERTimbau.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yj53GwTobb50",
        "outputId": "d6fab0e4-782d-4cb7-f483-d8db70de1031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk6de3k1sND5",
        "outputId": "12421c1d-ba88-4fdd-a764-97d3592d3460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix,f1_score,classification_report\n",
        "import numpy as np\n",
        "import re,unicodedata,nltk\n",
        "from nltk.corpus import stopwords\n",
        "from transformers import AutoTokenizer, TFBertForSequenceClassification, BertConfig\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import keras\n",
        "# import transformers\n",
        "# import tensorflow_hub as hub\n",
        "# from tqdm import tqdm\n",
        "# import pickle\n",
        "# from keras.models import Model\n",
        "# import keras.backend as K\n",
        "# from sklearn.metrics import confusion_matrix,f1_score,classification_report\n",
        "# import matplotlib.pyplot as plt\n",
        "# from keras.callbacks import ModelCheckpoint\n",
        "# import itertools\n",
        "# from keras.models import load_model\n",
        "# from transformers import TrainingArguments, Trainer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stops_nltk = nltk.corpus.stopwords.words('portuguese')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPHCJGIisND6",
        "outputId": "649309db-cb0a-4b2c-cce3-7753d601685c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found a GPU with the name: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
          ]
        }
      ],
      "source": [
        "gpus = tf.config.list_physical_devices(\"GPU\")\n",
        "if gpus:\n",
        "    for gpu in gpus:\n",
        "        print(\"Found a GPU with the name:\", gpu)\n",
        "else:\n",
        "    print(\"Failed to detect a GPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Mwtta_JsND6"
      },
      "outputs": [],
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def clean_stopwords_shortwords(w):\n",
        "    stopwords_list=stopwords.words('portuguese')\n",
        "    words = w.split()\n",
        "    clean_words = [word for word in words if (word not in stopwords_list) and len(word) > 2]\n",
        "    return \" \".join(clean_words)\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "    # w = re.sub(r\"([?.!,¿])\", r\" \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "    # w=clean_stopwords_shortwords(w)\n",
        "    w=re.sub(r'@\\w+', '',w)\n",
        "    return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tDMI-gFsND6"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel(\"/content/drive/MyDrive/PECE/resoucers/querys.xlsx\",sheet_name='Planilha1')\n",
        "df_to_use = df.loc[:,[\"Question\",\"NEW INTENT\"]].dropna()\n",
        "data=df_to_use.rename(columns = {'NEW INTENT': 'label', 'Question': 'text'}, inplace = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b13NKXKsND7",
        "outputId": "d30dac0f-610d-4d02-e864-eee0db41d355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available labels:  ['INFORMACAO_SOBRE_CLIENTE' 'LOCALIZAR_FUNCIONARIO'\n",
            " 'MOVIMENTACAO_QUADRO_DE_FUNCIONARIOS' 'DEPARTAMENTO_DO_FUNCIONARIO'\n",
            " 'LOCALIZAR_CLIENTE' 'CARGO_DO_FUNCIONARIO' 'METRICAS_DOS_CLIENTES'\n",
            " 'METRICAS_DE_PRODUCAO_DE_PRODUTOS' 'METRICAS_DO_QUADRO_DE_FUNCIONARIOS'\n",
            " 'METRICAS_DE_CUSTO_DE_PRODUTOS' 'LOCALIZAR_PRODUTOS_PELA_PRODUCAO'\n",
            " 'LOCALIZAR_PRODUTOS_PELO_CUSTO' 'QUANTIDADE_DE_DEPARTAMENTOS'\n",
            " 'METRICAS_DE_PRODUTOS_POR_CATEGORIA' 'TEMPO_DE_CASA_FUNCIONARIO']\n"
          ]
        }
      ],
      "source": [
        "data=data.dropna()                                                           # Drop NaN valuues, if any\n",
        "data=data.reset_index(drop=True)                                             # Reset index after dropping the columns/rows with NaN values\n",
        "data = shuffle(data)                                                         # Shuffle the dataset\n",
        "print('Available labels: ',data.label.unique())                              # Print all the unique labels in the dataset\n",
        "# data['text']=data['text'].map(preprocess_sentence)\n",
        "data['gt'] = pd.factorize(data['label'], sort=True)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPsBRRmmsND7",
        "outputId": "5f9cc5a0-3370-463d-cc1d-ba2b1b5566c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(182, 182)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "sentences=data['text']\n",
        "labels=data['gt']\n",
        "num_classes=len(data.label.unique())\n",
        "len(sentences),len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwkOs05KxTp-",
        "outputId": "01fc86e9-e13b-4e67-830f-c817b360e939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLhV07CtsND7",
        "outputId": "ee4c3022-abed-4766-e481-0d134bdaee25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier', 'bert/pooler/dense/bias:0', 'bert/pooler/dense/kernel:0']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_id = 'neuralmind/bert-base-portuguese-cased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = TFBertForSequenceClassification.from_pretrained(model_id,num_labels=num_classes,hidden_dropout_prob=0.5,attention_probs_dropout_prob=0.3)\n",
        "#mexer no dropout pelo menos 60%"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Hz4HvBl6LW2",
        "outputId": "b1fb5a2a-6dcc-43bd-bf25-44a51591439a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"_name_or_path\": \"neuralmind/bert-base-portuguese-cased\",\n",
              "  \"architectures\": [\n",
              "    \"BertForMaskedLM\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.3,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"directionality\": \"bidi\",\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.5,\n",
              "  \"hidden_size\": 768,\n",
              "  \"id2label\": {\n",
              "    \"0\": \"LABEL_0\",\n",
              "    \"1\": \"LABEL_1\",\n",
              "    \"2\": \"LABEL_2\",\n",
              "    \"3\": \"LABEL_3\",\n",
              "    \"4\": \"LABEL_4\",\n",
              "    \"5\": \"LABEL_5\",\n",
              "    \"6\": \"LABEL_6\",\n",
              "    \"7\": \"LABEL_7\",\n",
              "    \"8\": \"LABEL_8\",\n",
              "    \"9\": \"LABEL_9\",\n",
              "    \"10\": \"LABEL_10\",\n",
              "    \"11\": \"LABEL_11\",\n",
              "    \"12\": \"LABEL_12\",\n",
              "    \"13\": \"LABEL_13\",\n",
              "    \"14\": \"LABEL_14\"\n",
              "  },\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"label2id\": {\n",
              "    \"LABEL_0\": 0,\n",
              "    \"LABEL_1\": 1,\n",
              "    \"LABEL_10\": 10,\n",
              "    \"LABEL_11\": 11,\n",
              "    \"LABEL_12\": 12,\n",
              "    \"LABEL_13\": 13,\n",
              "    \"LABEL_14\": 14,\n",
              "    \"LABEL_2\": 2,\n",
              "    \"LABEL_3\": 3,\n",
              "    \"LABEL_4\": 4,\n",
              "    \"LABEL_5\": 5,\n",
              "    \"LABEL_6\": 6,\n",
              "    \"LABEL_7\": 7,\n",
              "    \"LABEL_8\": 8,\n",
              "    \"LABEL_9\": 9\n",
              "  },\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"output_past\": true,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"pooler_fc_size\": 768,\n",
              "  \"pooler_num_attention_heads\": 12,\n",
              "  \"pooler_num_fc_layers\": 3,\n",
              "  \"pooler_size_per_head\": 128,\n",
              "  \"pooler_type\": \"first_token_transform\",\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.35.2\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 29794\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMRP-st7sND7"
      },
      "outputs": [],
      "source": [
        "input_ids=[]\n",
        "attention_masks=[]\n",
        "\n",
        "for sent in sentences:\n",
        "    bert_inp=tokenizer.encode_plus(sent,add_special_tokens = True,max_length = 64, padding='max_length',return_attention_mask = True)\n",
        "    input_ids.append(bert_inp['input_ids'])\n",
        "    attention_masks.append(bert_inp['attention_mask'])\n",
        "\n",
        "input_ids=np.asarray(input_ids)\n",
        "attention_masks=np.array(attention_masks)\n",
        "labels=np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSGjUagjsND7"
      },
      "outputs": [],
      "source": [
        "train_inp,val_inp,train_label,val_label,train_mask,val_mask=train_test_split(input_ids,labels,attention_masks,test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBrp7wQasND7",
        "outputId": "11bf3c77-8134-4fc2-e339-ab5b62f76a37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_bert_for_sequence_classification_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  108923136 \n",
            "                                                                 \n",
            " dropout_607 (Dropout)       multiple                  0         \n",
            "                                                                 \n",
            " classifier (Dense)          multiple                  11535     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108934671 (415.55 MB)\n",
            "Trainable params: 108934671 (415.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "\n",
            "BERTimbau Model None\n"
          ]
        }
      ],
      "source": [
        "log_dir='/content/drive/MyDrive/PECE/tensorboard_data/tb_bertimbau'\n",
        "model_save_path='/content/drive/MyDrive/PECE/models/bertimbau_model.h5'\n",
        "\n",
        "callbacks = [\n",
        "             keras.callbacks.ModelCheckpoint(filepath=model_save_path,save_weights_only=True,monitor='val_loss',mode='min',save_best_only=True),\n",
        "             keras.callbacks.TensorBoard(log_dir=log_dir),\n",
        "             keras.callbacks.EarlyStopping(monitor=\"val_loss\",min_delta=1,patience=10,verbose=0,mode=\"min\",start_from_epoch=30, baseline=0.1)\n",
        "             ]\n",
        "\n",
        "print('\\nBERTimbau Model',model.summary())\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5,epsilon=1e-08)\n",
        "\n",
        "model.compile(loss=loss,optimizer=optimizer,metrics=[metric])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF1m48RHsND8",
        "outputId": "74f652e2-5198-4962-9b9f-7f4a6a11a980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "127/127 [==============================] - 10s 73ms/step - loss: 0.5948 - accuracy: 0.8346 - val_loss: 0.7110 - val_accuracy: 0.7455\n",
            "Epoch 2/60\n",
            "127/127 [==============================] - 6s 45ms/step - loss: 0.6676 - accuracy: 0.8268 - val_loss: 0.8348 - val_accuracy: 0.6909\n",
            "Epoch 3/60\n",
            "127/127 [==============================] - 6s 46ms/step - loss: 0.5793 - accuracy: 0.8268 - val_loss: 0.7592 - val_accuracy: 0.7091\n",
            "Epoch 4/60\n",
            "127/127 [==============================] - 6s 48ms/step - loss: 0.5242 - accuracy: 0.8504 - val_loss: 0.7808 - val_accuracy: 0.7636\n",
            "Epoch 5/60\n",
            "127/127 [==============================] - 9s 70ms/step - loss: 0.5045 - accuracy: 0.8819 - val_loss: 0.5882 - val_accuracy: 0.7636\n",
            "Epoch 6/60\n",
            "127/127 [==============================] - 6s 45ms/step - loss: 0.5245 - accuracy: 0.8740 - val_loss: 0.7169 - val_accuracy: 0.7636\n",
            "Epoch 7/60\n",
            "127/127 [==============================] - 6s 46ms/step - loss: 0.6245 - accuracy: 0.8268 - val_loss: 0.6732 - val_accuracy: 0.7455\n",
            "Epoch 8/60\n",
            "127/127 [==============================] - 9s 73ms/step - loss: 0.4134 - accuracy: 0.8819 - val_loss: 0.5767 - val_accuracy: 0.7636\n",
            "Epoch 9/60\n",
            "127/127 [==============================] - 6s 46ms/step - loss: 0.4904 - accuracy: 0.8346 - val_loss: 0.7975 - val_accuracy: 0.7091\n",
            "Epoch 10/60\n",
            "127/127 [==============================] - 6s 47ms/step - loss: 0.4097 - accuracy: 0.8583 - val_loss: 0.6457 - val_accuracy: 0.7636\n",
            "Epoch 11/60\n",
            "127/127 [==============================] - 6s 47ms/step - loss: 0.4252 - accuracy: 0.8819 - val_loss: 0.7476 - val_accuracy: 0.7455\n",
            "Epoch 12/60\n",
            "127/127 [==============================] - 6s 45ms/step - loss: 0.3749 - accuracy: 0.8976 - val_loss: 0.8406 - val_accuracy: 0.7091\n",
            "Epoch 13/60\n",
            "127/127 [==============================] - 6s 44ms/step - loss: 0.3087 - accuracy: 0.9213 - val_loss: 0.7181 - val_accuracy: 0.7273\n",
            "Epoch 14/60\n",
            "127/127 [==============================] - 6s 45ms/step - loss: 0.4085 - accuracy: 0.8661 - val_loss: 0.7102 - val_accuracy: 0.7455\n",
            "Epoch 15/60\n",
            "127/127 [==============================] - 6s 44ms/step - loss: 0.4057 - accuracy: 0.8819 - val_loss: 0.5916 - val_accuracy: 0.7818\n",
            "Epoch 16/60\n",
            "127/127 [==============================] - 9s 74ms/step - loss: 0.2966 - accuracy: 0.9291 - val_loss: 0.5338 - val_accuracy: 0.8000\n",
            "Epoch 17/60\n",
            "127/127 [==============================] - 6s 45ms/step - loss: 0.2280 - accuracy: 0.9528 - val_loss: 0.5444 - val_accuracy: 0.8545\n",
            "Epoch 18/60\n",
            "127/127 [==============================] - 6s 47ms/step - loss: 0.3083 - accuracy: 0.9213 - val_loss: 0.6235 - val_accuracy: 0.8364\n",
            "Epoch 19/60\n",
            "127/127 [==============================] - 9s 74ms/step - loss: 0.2522 - accuracy: 0.9528 - val_loss: 0.4978 - val_accuracy: 0.8364\n",
            "Epoch 20/60\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 0.2527 - accuracy: 0.9291 - val_loss: 0.4348 - val_accuracy: 0.8727\n",
            "Epoch 21/60\n",
            "127/127 [==============================] - 6s 45ms/step - loss: 0.2039 - accuracy: 0.9528 - val_loss: 0.4529 - val_accuracy: 0.8545\n",
            "Epoch 22/60\n",
            "127/127 [==============================] - 6s 48ms/step - loss: 0.2851 - accuracy: 0.9370 - val_loss: 0.6162 - val_accuracy: 0.8182\n",
            "Epoch 23/60\n",
            "127/127 [==============================] - 6s 46ms/step - loss: 0.1288 - accuracy: 0.9921 - val_loss: 0.4621 - val_accuracy: 0.8727\n",
            "Epoch 24/60\n",
            "127/127 [==============================] - 6s 46ms/step - loss: 0.1683 - accuracy: 0.9528 - val_loss: 0.6247 - val_accuracy: 0.8182\n",
            "Epoch 25/60\n",
            "127/127 [==============================] - 6s 45ms/step - loss: 0.1082 - accuracy: 0.9843 - val_loss: 0.4627 - val_accuracy: 0.8545\n",
            "Epoch 26/60\n",
            "127/127 [==============================] - 6s 46ms/step - loss: 0.1826 - accuracy: 0.9606 - val_loss: 0.4969 - val_accuracy: 0.8545\n",
            "Epoch 27/60\n",
            "127/127 [==============================] - 6s 44ms/step - loss: 0.1831 - accuracy: 0.9528 - val_loss: 0.5754 - val_accuracy: 0.8545\n",
            "Epoch 28/60\n",
            "127/127 [==============================] - 9s 75ms/step - loss: 0.2087 - accuracy: 0.9370 - val_loss: 0.4197 - val_accuracy: 0.8727\n",
            "Epoch 29/60\n",
            "127/127 [==============================] - 6s 44ms/step - loss: 0.1095 - accuracy: 0.9764 - val_loss: 0.4356 - val_accuracy: 0.8727\n",
            "Epoch 30/60\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 0.1668 - accuracy: 0.9449 - val_loss: 0.3019 - val_accuracy: 0.9091\n",
            "Epoch 31/60\n",
            "127/127 [==============================] - 6s 45ms/step - loss: 0.1941 - accuracy: 0.9370 - val_loss: 0.4722 - val_accuracy: 0.8182\n",
            "Epoch 32/60\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 0.1666 - accuracy: 0.9528 - val_loss: 0.3853 - val_accuracy: 0.8364\n",
            "Epoch 33/60\n",
            "127/127 [==============================] - 6s 45ms/step - loss: 0.1843 - accuracy: 0.9291 - val_loss: 0.3861 - val_accuracy: 0.8727\n",
            "Epoch 34/60\n",
            "127/127 [==============================] - 6s 46ms/step - loss: 0.1361 - accuracy: 0.9764 - val_loss: 0.4998 - val_accuracy: 0.8545\n",
            "Epoch 35/60\n",
            "127/127 [==============================] - 6s 43ms/step - loss: 0.0884 - accuracy: 0.9843 - val_loss: 0.5966 - val_accuracy: 0.8545\n",
            "Epoch 36/60\n",
            "127/127 [==============================] - 6s 46ms/step - loss: 0.1359 - accuracy: 0.9685 - val_loss: 0.4190 - val_accuracy: 0.8364\n",
            "Epoch 37/60\n",
            "127/127 [==============================] - 6s 44ms/step - loss: 0.1830 - accuracy: 0.9449 - val_loss: 0.5254 - val_accuracy: 0.8364\n",
            "Epoch 38/60\n",
            "127/127 [==============================] - 6s 46ms/step - loss: 0.1906 - accuracy: 0.9528 - val_loss: 0.3269 - val_accuracy: 0.9091\n",
            "Epoch 39/60\n",
            "127/127 [==============================] - 6s 44ms/step - loss: 0.0910 - accuracy: 0.9764 - val_loss: 0.4528 - val_accuracy: 0.8545\n",
            "Epoch 40/60\n",
            "127/127 [==============================] - 6s 45ms/step - loss: 0.2292 - accuracy: 0.9134 - val_loss: 0.4395 - val_accuracy: 0.8364\n"
          ]
        }
      ],
      "source": [
        "history=model.fit([train_inp,train_mask],train_label,batch_size=1,epochs=60,validation_data=([val_inp,val_mask],val_label),callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "import json\n",
        "\n",
        "# Convert and write JSON object to file\n",
        "with open(\"/content/drive/MyDrive/PECE/resoucers/dict_classes.json\", \"w\") as outfile:\n",
        "    json.dump(dict_classes, outfile)\n",
        "\n"
      ],
      "metadata": {
        "id": "4otKR--hw-lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_classes = dict([i for i in zip(data['gt'].astype(str).values,data['label'].values)])\n",
        "labels_dict = [dict_classes[str(i)] for i in [*range(len(list(dict_classes.keys())))]]"
      ],
      "metadata": {
        "id": "jTx1AGh4c4q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tN-eyAtsND8",
        "outputId": "0898839c-872d-4d4b-d2d4-2379e6b7a4dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier', 'bert/pooler/dense/bias:0', 'bert/pooler/dense/kernel:0']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55/55 [==============================] - 4s 8ms/step\n",
            "F1 score 0.9090909090909091\n",
            "Classification Report\n",
            "                                     precision    recall  f1-score   support\n",
            "\n",
            "               CARGO_DO_FUNCIONARIO       1.00      1.00      1.00         5\n",
            "        DEPARTAMENTO_DO_FUNCIONARIO       1.00      1.00      1.00         4\n",
            "           INFORMACAO_SOBRE_CLIENTE       1.00      0.75      0.86         4\n",
            "                  LOCALIZAR_CLIENTE       0.67      1.00      0.80         2\n",
            "              LOCALIZAR_FUNCIONARIO       1.00      1.00      1.00         4\n",
            "   LOCALIZAR_PRODUTOS_PELA_PRODUCAO       0.75      1.00      0.86         3\n",
            "      LOCALIZAR_PRODUTOS_PELO_CUSTO       0.86      1.00      0.92         6\n",
            "      METRICAS_DE_CUSTO_DE_PRODUTOS       0.50      1.00      0.67         1\n",
            "   METRICAS_DE_PRODUCAO_DE_PRODUTOS       1.00      1.00      1.00         5\n",
            " METRICAS_DE_PRODUTOS_POR_CATEGORIA       1.00      0.25      0.40         4\n",
            "              METRICAS_DOS_CLIENTES       0.86      1.00      0.92         6\n",
            " METRICAS_DO_QUADRO_DE_FUNCIONARIOS       1.00      0.67      0.80         3\n",
            "MOVIMENTACAO_QUADRO_DE_FUNCIONARIOS       1.00      1.00      1.00         3\n",
            "        QUANTIDADE_DE_DEPARTAMENTOS       1.00      1.00      1.00         2\n",
            "          TEMPO_DE_CASA_FUNCIONARIO       1.00      1.00      1.00         3\n",
            "\n",
            "                           accuracy                           0.91        55\n",
            "                          macro avg       0.91      0.91      0.88        55\n",
            "                       weighted avg       0.93      0.91      0.90        55\n",
            "\n",
            "Training and saving built model.....\n"
          ]
        }
      ],
      "source": [
        "model_id = 'neuralmind/bert-base-portuguese-cased'\n",
        "model_save_path='/content/drive/MyDrive/PECE/models/bertimbau_model.h5'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5,epsilon=1e-08)\n",
        "\n",
        "trained_model = TFBertForSequenceClassification.from_pretrained(model_id,num_labels=num_classes)\n",
        "# trained_model.compile(loss=loss,optimizer=optimizer, metrics=[metric])\n",
        "trained_model.load_weights(model_save_path)\n",
        "\n",
        "preds = trained_model.predict([val_inp,val_mask],batch_size=1)\n",
        "pred_labels = np.argmax(preds.logits, axis=1)\n",
        "f1 = f1_score(val_label,pred_labels,average='micro')\n",
        "print('F1 score',f1)\n",
        "print('Classification Report')\n",
        "print(classification_report(val_label,pred_labels,target_names=labels_dict))\n",
        "\n",
        "print('Training and saving built model.....')\n",
        "\n",
        "#FOCO NO RECALL > 80%\n",
        "#APOS ISSO PRECISAO"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_classes"
      ],
      "metadata": {
        "id": "Qp_2YbI0vujo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2860ee16-e0f9-4436-fbfd-af781ae35b1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{10: 'METRICAS_DOS_CLIENTES',\n",
              " 0: 'CARGO_DO_FUNCIONARIO',\n",
              " 12: 'MOVIMENTACAO_QUADRO_DE_FUNCIONARIOS',\n",
              " 9: 'METRICAS_DE_PRODUTOS_POR_CATEGORIA',\n",
              " 11: 'METRICAS_DO_QUADRO_DE_FUNCIONARIOS',\n",
              " 6: 'LOCALIZAR_PRODUTOS_PELO_CUSTO',\n",
              " 3: 'LOCALIZAR_CLIENTE',\n",
              " 4: 'LOCALIZAR_FUNCIONARIO',\n",
              " 7: 'METRICAS_DE_CUSTO_DE_PRODUTOS',\n",
              " 2: 'INFORMACAO_SOBRE_CLIENTE',\n",
              " 1: 'DEPARTAMENTO_DO_FUNCIONARIO',\n",
              " 8: 'METRICAS_DE_PRODUCAO_DE_PRODUTOS',\n",
              " 5: 'LOCALIZAR_PRODUTOS_PELA_PRODUCAO',\n",
              " 13: 'QUANTIDADE_DE_DEPARTAMENTOS',\n",
              " 14: 'TEMPO_DE_CASA_FUNCIONARIO'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict([i for i in zip(data['gt'].values,data['label'].values)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTFC0GhNvdL9",
        "outputId": "e781ba5d-cb0f-4236-b64a-4b2f608859b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{10: 'METRICAS_DOS_CLIENTES',\n",
              " 0: 'CARGO_DO_FUNCIONARIO',\n",
              " 12: 'MOVIMENTACAO_QUADRO_DE_FUNCIONARIOS',\n",
              " 9: 'METRICAS_DE_PRODUTOS_POR_CATEGORIA',\n",
              " 11: 'METRICAS_DO_QUADRO_DE_FUNCIONARIOS',\n",
              " 6: 'LOCALIZAR_PRODUTOS_PELO_CUSTO',\n",
              " 3: 'LOCALIZAR_CLIENTE',\n",
              " 4: 'LOCALIZAR_FUNCIONARIO',\n",
              " 7: 'METRICAS_DE_CUSTO_DE_PRODUTOS',\n",
              " 2: 'INFORMACAO_SOBRE_CLIENTE',\n",
              " 1: 'DEPARTAMENTO_DO_FUNCIONARIO',\n",
              " 8: 'METRICAS_DE_PRODUCAO_DE_PRODUTOS',\n",
              " 5: 'LOCALIZAR_PRODUTOS_PELA_PRODUCAO',\n",
              " 13: 'QUANTIDADE_DE_DEPARTAMENTOS',\n",
              " 14: 'TEMPO_DE_CASA_FUNCIONARIO'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c4vBTD1sND8"
      },
      "outputs": [],
      "source": [
        "teste = \"Quantos funcionarios tem no setor de marketing?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xTs2vL-sND8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcc352e4-111f-40c1-fc43-2f7dafa03e7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "input_ids=[]\n",
        "attention_masks=[]\n",
        "\n",
        "bert_inp=tokenizer.encode_plus(teste,add_special_tokens = True,max_length =64, pad_to_max_length = True,return_attention_mask = True)\n",
        "input_ids.append(bert_inp['input_ids'])\n",
        "attention_masks.append(bert_inp['attention_mask'])\n",
        "\n",
        "input_ids=np.asarray(input_ids)\n",
        "attention_masks=np.array(attention_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIgj9xrusND8",
        "outputId": "d849ba4c-9c30-4594-df18-ba14c1c7e7e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "preds = trained_model.predict([input_ids,attention_masks],batch_size=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEnHeB6asND8"
      },
      "outputs": [],
      "source": [
        "teste=np.where(preds.logits>=0.50,1,0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds.logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lll96JGzIBUL",
        "outputId": "d1881848-4e64-43d0-f0db-ac8fcc6cd0c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.7778617 , -0.53754526, -0.90348244, -0.8599582 ,  1.6856688 ,\n",
              "        -0.44356814, -0.70820117, -1.3051971 , -0.49319133, -0.8795275 ,\n",
              "         0.80512565,  5.828703  , -0.9201504 ,  2.0146732 , -0.72137386]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,col in enumerate(teste[0]):\n",
        "  if col == 1:\n",
        "    print(dict_classes[i],preds.logits[0][i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "o4BOl4taH7oY",
        "outputId": "bf8219bb-38fa-4905-e489-6e45fba7697a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "4",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-97e05b19ed12>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteste\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_classes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 4"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqOkPgZtsND8"
      },
      "outputs": [],
      "source": [
        "pred_labels = np.argmax(preds.logits, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOMIJqscsND8",
        "outputId": "c5d64d5e-8b87-46c1-a461-28d61466ae7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([11])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "pred_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECvfCz9UsND9"
      },
      "outputs": [],
      "source": [
        "guia = data.label.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_NvXMggwsND9",
        "outputId": "a982ca90-23f1-41d7-fbbc-67711d096d29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'METRICAS_DO_QUADRO_DE_FUNCIONARIOS'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "dict_classes[str(pred_labels[0])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBD1G7gXsND9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}